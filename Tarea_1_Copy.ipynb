{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edugaitann81/Mercado_libre_prueba/blob/main/Tarea_1_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BFwl_iaUj_I"
      },
      "source": [
        "# TAREA 1: Métodos de aprendizaje conjunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac79xDFmUj_K"
      },
      "source": [
        "## 1. Preguntas conceptuales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK8NhErzUj_K"
      },
      "source": [
        "### 1.1. ¿Si un algoritmo `gradient boosting ensemble` muestra `sobreajuste`, ¿debería aumentar o disminuir la tasa de aprendizaje? Argumente su respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AULA7UykUj_K"
      },
      "source": [
        "**Respuesta:**\n",
        "##### Si hay sobreajuste en un modelo, para este caso gradient Boosting, significa que el modelo funciona muy bien con los datos de entrenamiento pero mal con los datos nuevos o test, por lo tanto al estar sobreajustado, probablemente la tasa de aprendizaje sea alta, ya que el modelo aprende muy rapido, cada nuevo arbol que se añade al modelo tiene un gran impacto, ajustandose muy bien a los datos de entrenamiento, capturando el ruido, pero no generaliza bien con los datos nuevos.\n",
        "##### Lo que deberia buscarse para mitigar el sobreajuste es una tasa de aprendizaje mas baja, esto puede lograrse aunmentando el numero de estimadores o arboles, buscando un modelo mas robusto, que no se ajuste de una forma tan precisa a las particularidades de los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUG8PyfkUj_L"
      },
      "source": [
        "### 1.2. Si ha entrenado 5 `modelos diferentes` de clasificación con exactamente los mismos datos de entrenamiento y todos ellos alcanzan una exactitud (`accuracy`) del $95\\%$, ¿existe alguna posibilidad de que pueda combinar estos modelos para obtener mejores resultados? Si es así, ¿cómo? Si no, ¿por qué?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nm-EGZVUj_L"
      },
      "source": [
        "**Respuesta:**\n",
        "######SI, existe la posibilidad de combinar estos modelos, para mejorar los resultados, como se vio en las primeras clases existen metedologías como:\n",
        "######1. Metodo por Votación: Modelos de diferentes tipos, consiste en tomar una decisón a traves de Votos, tiene 2 clases\n",
        " ###### Dura: Cada modelo hace una predicción, y la clase que recibe más votos es la decisón Final (Regla de la Mayoria).\n",
        "######  Suave: Se calcula el valor promedio de cada probabilidad y se determina la probabilidad más alta, como resultado final      \n",
        "######2. Bagging: Entrena múltiples versiones del mismo modelo en diferentes subconjuntos del conjunto de datos de entrenamiento y luego combina sus predicciones, por ejemplo Random Forest, aquí se generan varios arboles de decisón y se combinan sus prediccones.  \n",
        "######3. Boosting: Consiste en entrenar los modelos de manera secuencial, donde cada modelo intenta corregir los errores de los modelos anteriores. en clase se vio el adaBoost como ejemplo pero tambien uno de los ejemplos más comunes, es el Gradient Boosting, y otros como XGBoost y LGBM.\n",
        "\n",
        "######Ventajas: Reducción de Varianza, Robustez, Mejora la generalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNVNY1S8Uj_L"
      },
      "source": [
        "### 1.3. Suponga que en el escenario de la pregunta `1.2` se combinan los `5` clasificadores base mediante el método de `voto mayoriatario duro`. Calcule el error del clasificador conjunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsw6QuciUj_L"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "fquGDa9DCEuT"
      },
      "source": [
        "Si cada uno de los 5 modelos de clasificación tienen un accuracy del 95%, esto quiere decir que cada clasificación tiene un error del 5%, al definir:\n",
        "n = 5 como numero de clasificadores,\n",
        "p = 0.05 probabilidad de error de un clasificador,\n",
        "q = 1 - p probabilidad acierto\n",
        "\n",
        "Entiendo que para calcular el error de clasificador conjunto en un sistema de votación dura, necesitamos considerar la probabilidad de que más de la mitad de los clasificadores se equivoquen, por tanto asumiendo que más de la mitad de los clasificadores son inclorrectos el error conjunto podria ser del 0.1158%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf2VRIWBCEuT",
        "outputId": "132919df-fb0c-4408-ed8e-bd6a3f001417"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0011581250000000003"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from math import comb\n",
        "\n",
        "# Parámetros\n",
        "n = 5\n",
        "p = 0.05\n",
        "q = 1 - p\n",
        "\n",
        "# Calculo el error de clasificador conjunto (votación dura)\n",
        "P_error_conjunto = 0\n",
        "\n",
        "# Suma de las probabilidades de 3 a 5 errores\n",
        "for k in range(3, n+1):\n",
        "    P_error_conjunto += comb(n, k) * (p**k) * (q**(n-k))\n",
        "\n",
        "P_error_conjunto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCYR8LssUj_M"
      },
      "source": [
        "### 1.4. ¿Si un algoritmo `Adaboost` muestra `subajuste`, ¿qué hiperparámetros debería ajustar y cómo? Argumente su respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNpWittkCEuW"
      },
      "source": [
        "#### Respuesta"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "ViPIIkorCEuW"
      },
      "source": [
        "Si un algoritmo como el AdaBoost presenta sobreajuste, esto problablemente se debe a que está teniendo dificultades para aprender adecuadamente los patrones en los datos de entrenamiento, lo que puede llevar a un rendimiento deficiente en los datos de prueba, para ajustar esto los hiperparametros a ajustar podrian ser:\n",
        "\n",
        "1. Numero de estimadores, (n_estimators): Controla cuantos modelos debiles, para este caso Arboles de decisión, la idea es que  al combinarse se forme un modelo fuerte de Adaboost.\n",
        "\n",
        "2. Tasa de aprendizaje (Learning_rate): Una tasa de aprendizaje más alta puede hacer que el modelo se ajuste más rápidamente a los datos. igual hay que tener presente el sobreajuste y como prevenirlo.\n",
        "\n",
        "3. Profundidad del Arbol (base_estimator__max_depth): controla la profundidad máxima de los árboles de decisión que se utilizan como clasificadores débiles en AdaBoost, Reducir la profundidad máxima puede ayudar a evitar el sobreajuste y mejorar la generalización del modelo\n",
        "\n",
        "Ejemplo:\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.1, 0.5, 1.0],\n",
        "    'base_estimator__max_depth': [1, 2, 3]\n",
        "}\n",
        "\n",
        "previamente será necesario definir las bases de Train (X, Y), Test (X, Y), establecer una semilla, y con los hiperparametros definidos usar GridSearchCV para buscar la mejor configuración."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omajRCCaUj_M"
      },
      "source": [
        "## 2. Ejercicio(s) práctico(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfoMVYN5Uj_M"
      },
      "source": [
        "El conjunto de datos `mnist_784`, contiene 70.000 pequeñas imágenes de dígitos escritos a mano por estudiantes de secundaria y empleados de la Oficina del Censo de EE.UU. Es posible acceder a este dataset medinte las siguientes instrucciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sbrs4g8HUj_M",
        "outputId": "847ea5ae-7654-420e-addd-066b7ba31142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 22.6 s, sys: 431 ms, total: 23 s\n",
            "Wall time: 28.9 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
              "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "\n",
              "       777  778  779  780  781  782  783  \n",
              "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "...    ...  ...  ...  ...  ...  ...  ...  \n",
              "69995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "69996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "69997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "69998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "69999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[70000 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ac0d54d-e008-40c0-b895-b9c67bded89b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70000 rows × 784 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ac0d54d-e008-40c0-b895-b9c67bded89b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ac0d54d-e008-40c0-b895-b9c67bded89b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ac0d54d-e008-40c0-b895-b9c67bded89b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c4f6231a-b9d6-42b0-830d-4a38d76235f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4f6231a-b9d6-42b0-830d-4a38d76235f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c4f6231a-b9d6-42b0-830d-4a38d76235f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', as_frame=False)\n",
        "X, y = mnist.data, mnist.target\n",
        "\n",
        "pd.DataFrame(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwU72grNtioo",
        "outputId": "3b8bea63-503f-48cd-e802-a8d55e84b5af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255.0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3_QSRobfUj_O",
        "outputId": "95fb5478-8722-4cb2-b2de-b315dcc417ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La etiqueta de esta imagen es:  3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "##Visualización\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_digit(image_data):\n",
        "    image = image_data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "print(\"La etiqueta de esta imagen es: \", y[12])\n",
        "plot_digit(X[12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsEuiNydUj_O"
      },
      "source": [
        "- 2.1 Escale todas las `784` variables con el método `min-max`; pero usando en máximo y el mínimo globales, en lugar de los de cada columna. Vrase el `ejercicio 0312` del capítulo 5, unidad 8 (`ensemble algorithms`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Calculo del máximo y mínimo globales\n",
        "global_max = np.max(X)\n",
        "global_min = np.min(X)\n",
        "\n",
        "# Escalar con MinMaxScaler los valores globales\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_scaler_global = scaler.fit_transform(X - global_min) / (global_max - global_min)\n",
        "\n",
        "print(\"Mínimo:\", np.min(X_scaler_global))\n",
        "print(\"Máximo:\", np.max(X_scaler_global))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhEZvE0nPYl1",
        "outputId": "8edffc22-915c-442f-ee68-918162e3d4f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mínimo: 0.0\n",
            "Máximo: 0.00392156862745098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabla de datos escalada\n",
        "X_scaler_global"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x1OiIwiPZkE",
        "outputId": "8cc49c0f-b54c-4f62-e3ac-8c03e3b9b127"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensiones\n",
        "X_scaler_global.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUMsoVHDPj2J",
        "outputId": "f05950ce-39f2-4554-f260-e928652b0543"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGxXb1DnUj_O"
      },
      "source": [
        "- 2.2 Divida los datos en un conjunto de entrenamiento y un conjunto de prueba (utilizar $60.000$ registros para el entrenamiento y $10.000$ para prueba). Luego, entrene los siguientes clasificadores optimizando los `hiperparámetros` más representativos (excepto los de regularización) mediante la `validación cruzada `:\n",
        "\n",
        "  - clasificador SVM.\n",
        "  - Regresión logística\n",
        "  - Naive Bayes\n",
        "  - K-vecinos\n",
        "  - Árbol de decisión\n",
        "\n",
        "  Compare los rendimientos de cada uno de ellos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divido los datos en Train y Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# datos en Train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaler_global, y, test_size=10000, train_size=60000, random_state=42)\n",
        "\n",
        "print(X_train.shape[0])\n",
        "print(X_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3vo84z7Pq5z",
        "outputId": "21787edb-4c1a-4247-d3e2-056a326b2983"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Me fue necesario reducir a un 10% el conjunto de train, ya que con los 60k dura más de 3.45 hrs y no ejecuta, incluso modelo por modelo, por eso trabajo con el 10%"
      ],
      "metadata": {
        "id": "mnM19bV02ona"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducir el tamaño del conjunto de datos de entrenamiento\n",
        "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, train_size=0.1, stratify=y_train, random_state=42)\n",
        "\n",
        "print(X_train_sample.shape[0])\n",
        "print(y_train_sample.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0culgEKyLj5",
        "outputId": "018d436c-12dd-4e0b-8702-cd1974225432"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000\n",
            "6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por tiempo ejecuto clasificador por clasificador ya que el proceso al tiempo tardo 3 horas y no termino,\n",
        "###### Nota: Utilizo RandomizedSearchCV, como opción mas rapida explora una cantidad fija de combinaciones, por cuestión de maquina y tiempo"
      ],
      "metadata": {
        "id": "dUugARh41yhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# SVM\n",
        "########################\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV # opción mas rapida explora una cantidad fija de combinaciones\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Parámetros SVM\n",
        "svm_params = {\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Optimización y validación cruzada para SVM\n",
        "svm = SVC(probability=True)  # Habilita cálculo de probabilidades\n",
        "random_search_svm = RandomizedSearchCV(svm, svm_params, cv=3, scoring='accuracy', n_iter=5, n_jobs=-1, random_state=42)\n",
        "random_search_svm.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "best_svm = random_search_svm.best_estimator_\n",
        "joblib.dump(best_svm, 'SVM_model.pkl')  # Guardar el mejor SVM\n",
        "\n",
        "print(f\"Mejor configuración para SVM:\")\n",
        "print(random_search_svm.best_params_)\n",
        "print(f\"Precisión media de validación cruzada: {random_search_svm.best_score_:.4f}\")\n",
        "joblib.dump(random_search_svm.best_params_, 'svm_best_params.pkl')\n",
        "\n",
        "# Evaluación en el conjunto de prueba\n",
        "y_pred_svm = best_svm.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "joblib.dump(y_pred_svm, 'SVM_pred.pkl')\n",
        "joblib.dump(accuracy_svm, 'SVM_accuracy.pkl')\n",
        "\n",
        "print(f\"SVM: Precisión en el conjunto de prueba = {accuracy_svm:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEamEAMyPrOT",
        "outputId": "4bacbdf0-f030-4e88-d54d-7132ac3b9d08"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración para SVM:\n",
            "{'kernel': 'rbf', 'gamma': 'scale'}\n",
            "Precisión media de validación cruzada: 0.9493\n",
            "SVM: Precisión en el conjunto de prueba = 0.9504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# Regresión Logistica\n",
        "#################################\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Parámetros para Regresión Logística\n",
        "logreg_params = {\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
        "}\n",
        "\n",
        "# Optimización y validación cruzada para Regresión Logística\n",
        "logreg = LogisticRegression()\n",
        "random_search_logreg = RandomizedSearchCV(logreg, logreg_params, cv=5, scoring='accuracy', n_iter=10, n_jobs=-1, random_state=42)\n",
        "random_search_logreg.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "best_logreg = random_search_logreg.best_estimator_\n",
        "joblib.dump(best_logreg, 'LogisticRegression_model.pkl') # Voy guardando la mejor RL\n",
        "\n",
        "print(f\"Mejor configuración para Regresión Logística:\")\n",
        "print(random_search_logreg.best_params_)\n",
        "print(f\"Precisión media de validación cruzada: {random_search_logreg.best_score_:.4f}\")\n",
        "joblib.dump(random_search_logreg.best_params_, 'logreg_best_params.pkl')\n",
        "\n",
        "# Evaluación en el conjunto de prueba\n",
        "y_pred_logreg = best_logreg.predict(X_test)\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "joblib.dump(y_pred_logreg, 'LogisticRegression_pred.pkl')\n",
        "joblib.dump(accuracy_logreg, 'LogisticRegression_accuracy.pkl')\n",
        "\n",
        "print(f\"Regresión Logística: Precisión en el conjunto de prueba = {accuracy_logreg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsxl-WEePrd-",
        "outputId": "750ae218-a03d-4b16-8f8d-7d1a78328dba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración para Regresión Logística:\n",
            "{'solver': 'newton-cg'}\n",
            "Precisión media de validación cruzada: 0.3927\n",
            "Regresión Logística: Precisión en el conjunto de prueba = 0.4564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################\n",
        "# K-Vecinos\n",
        "################################\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Parámetros para K-Vecinos\n",
        "knn_params = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
        "}\n",
        "\n",
        "# Optimización y validación cruzada para K-Vecinos\n",
        "knn = KNeighborsClassifier()\n",
        "random_search_knn = RandomizedSearchCV(knn, knn_params, cv=5, scoring='accuracy', n_iter=10, n_jobs=-1, random_state=42)\n",
        "random_search_knn.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "best_knn = random_search_knn.best_estimator_\n",
        "joblib.dump(best_knn, 'KNN_model.pkl') # Guardo el mejor KV\n",
        "\n",
        "print(f\"Mejor configuración para K-Vecinos:\")\n",
        "print(random_search_knn.best_params_)\n",
        "print(f\"Precisión media de validación cruzada: {random_search_knn.best_score_:.4f}\")\n",
        "joblib.dump(random_search_knn.best_params_, 'KNN_best_params.pkl')\n",
        "\n",
        "# Evaluación en el conjunto de prueba\n",
        "y_pred_knn = best_knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "joblib.dump(y_pred_knn, 'KNN_pred.pkl')\n",
        "joblib.dump(accuracy_knn, 'KNN_accuracy.pkl')\n",
        "\n",
        "print(f\"K-Vecinos: Precisión en el conjunto de prueba = {accuracy_knn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuxFWa2IPrtC",
        "outputId": "73e8c58e-610f-4717-eaa9-b8d787e37483"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración para K-Vecinos:\n",
            "{'n_neighbors': 7, 'algorithm': 'auto'}\n",
            "Precisión media de validación cruzada: 0.9342\n",
            "K-Vecinos: Precisión en el conjunto de prueba = 0.9299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# Arbol Decision\n",
        "############################\n",
        "from sklearn.model_selection import RandomizedSearchCV # opción mas rapida explora una cantidad fija de combinaciones\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import joblib\n",
        "\n",
        "# Parámetros para Árbol de Decisión\n",
        "tree_params = {\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Optimización y validación cruzada para Árbol de Decisión\n",
        "tree = DecisionTreeClassifier()\n",
        "random_search_tree = RandomizedSearchCV(tree, tree_params, cv=5, scoring='accuracy', n_iter=10, n_jobs=-1, random_state=42)\n",
        "random_search_tree.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "best_tree = random_search_tree.best_estimator_\n",
        "joblib.dump(best_tree, 'DecisionTree_model.pkl') #Guardo el mejor\n",
        "\n",
        "print(f\"Mejor configuración para Árbol de Decisión:\")\n",
        "print(random_search_tree.best_params_)\n",
        "print(f\"Precisión media de validación cruzada: {random_search_tree.best_score_:.4f}\")\n",
        "joblib.dump(random_search_tree.best_params_, 'DecisionTree_best_params.pkl')\n",
        "\n",
        "# Evaluación en el conjunto de prueba\n",
        "y_pred_tree = best_tree.predict(X_test)\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "joblib.dump(y_pred_tree, 'DecisionTree_pred.pkl')\n",
        "joblib.dump(accuracy_tree, 'DecisionTree_accuracy.pkl')\n",
        "\n",
        "print(f\"Árbol de Decisión: Precisión en el conjunto de prueba = {accuracy_tree:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUU3B5uPPr_j",
        "outputId": "9e8c8906-5a82-444f-9ba9-af642c9e0570"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración para Árbol de Decisión:\n",
            "{'min_samples_split': 5, 'max_depth': 10}\n",
            "Precisión media de validación cruzada: 0.7865\n",
            "Árbol de Decisión: Precisión en el conjunto de prueba = 0.7899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################\n",
        "# Naive Bayes\n",
        "################################\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Entrenamiento y validación cruzada para Naive Bayes\n",
        "nb = GaussianNB()\n",
        "random_search_nb = RandomizedSearchCV(nb, {}, cv=5, scoring='accuracy', n_iter=10, n_jobs=-1, random_state=42)\n",
        "random_search_nb.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "best_nb = random_search_nb.best_estimator_\n",
        "joblib.dump(best_nb, 'NaiveBayes_model.pkl') # Guardo\n",
        "\n",
        "print(f\"Mejor configuración para Naive Bayes:\")\n",
        "print(random_search_nb.best_params_)\n",
        "print(f\"Precisión media de validación cruzada: {random_search_nb.best_score_:.4f}\")\n",
        "\n",
        "# Evaluación en el conjunto de prueba\n",
        "y_pred_nb = best_nb.predict(X_test)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "joblib.dump(y_pred_nb, 'NaiveBayes_pred.pkl')\n",
        "joblib.dump(accuracy_nb, 'NaiveBayes_accuracy.pkl')\n",
        "\n",
        "print(f\"Naive Bayes: Precisión en el conjunto de prueba = {accuracy_nb:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHEzC7JS3koD",
        "outputId": "75059716-7b6d-420c-b685-90d88f74ac9a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración para Naive Bayes:\n",
            "{}\n",
            "Precisión media de validación cruzada: 0.6060\n",
            "Naive Bayes: Precisión en el conjunto de prueba = 0.6105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################################\n",
        "# Comparación\n",
        "###################################\n",
        "import joblib\n",
        "\n",
        "# Cargar las precisiones de los modelos\n",
        "accuracy_svm = joblib.load('SVM_accuracy.pkl')\n",
        "accuracy_logreg = joblib.load('LogisticRegression_accuracy.pkl')\n",
        "accuracy_knn = joblib.load('KNN_accuracy.pkl')\n",
        "accuracy_tree = joblib.load('DecisionTree_accuracy.pkl')\n",
        "accuracy_nb = joblib.load('NaiveBayes_accuracy.pkl')\n",
        "\n",
        "# Comparar los rendimientos\n",
        "print(\"\\nComparación de rendimientos en el conjunto de prueba:\")\n",
        "print(f\"SVM: Precisión = {accuracy_svm:.4f}\")\n",
        "print(f\"Regresión Logística: Precisión = {accuracy_logreg:.4f}\")\n",
        "print(f\"K-Vecinos: Precisión = {accuracy_knn:.4f}\")\n",
        "print(f\"Árbol de Decisión: Precisión = {accuracy_tree:.4f}\")\n",
        "print(f\"Naive Bayes: Precisión = {accuracy_nb:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfSxEQku3kvk",
        "outputId": "f19ad5e9-3a23-4e9f-cf02-99273b1c46b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparación de rendimientos en el conjunto de prueba:\n",
            "SVM: Precisión = 0.9504\n",
            "Regresión Logística: Precisión = 0.4564\n",
            "K-Vecinos: Precisión = 0.9299\n",
            "Árbol de Decisión: Precisión = 0.7891\n",
            "Naive Bayes: Precisión = 0.6105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESPUESTA: El mejor modelo en este momento en cuanto a accuracy es el SVM con un 0.9504, diferencia de 0.0205 de accuracy con el K-vecinos que es el segundo mejor, y 0.1613 con el decision Tree que es el tercero mejor\n"
      ],
      "metadata": {
        "id": "GGgVCv4U8cvp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekdw0F8NUj_O"
      },
      "source": [
        "- 2.3 Utilizando la combinación de hiperparámetroas más óptima para cada uno de los modelos anteriores, construya un clasificador por `voto mayoritario` tanto tipo `hard` como tipo `soft`. Elejia el más `eficiente` de los dos métodos y compare su rendimientro contra el mejor clasificador individual del numeral anterior."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Cargue de los mejores modelos guardados\n",
        "best_svm = joblib.load('SVM_model.pkl')\n",
        "best_logreg = joblib.load('LogisticRegression_model.pkl')\n",
        "best_knn = joblib.load('KNN_model.pkl')\n",
        "best_dtree = joblib.load('DecisionTree_model.pkl')\n",
        "best_nb = joblib.load('NaiveBayes_model.pkl')\n",
        "\n",
        "# Clasificador por voto mayoritario (hard voting)\n",
        "voting_clf_hard = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', best_svm),\n",
        "        ('logreg', best_logreg),\n",
        "        ('knn', best_knn),\n",
        "        ('dtree', best_dtree),\n",
        "        ('nb', best_nb)\n",
        "    ], voting='hard'\n",
        ")\n",
        "\n",
        "# Clasificador por voto mayoritario (soft voting)\n",
        "voting_clf_soft = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', best_svm),\n",
        "        ('logreg', best_logreg),\n",
        "        ('knn', best_knn),\n",
        "        ('dtree', best_dtree),\n",
        "        ('nb', best_nb)\n",
        "    ], voting='soft'\n",
        ")\n",
        "\n",
        "# Entrenar el clasificador por voto mayoritario (hard voting)\n",
        "voting_clf_hard.fit(X_train_sample, y_train_sample)\n",
        "y_pred_hard = voting_clf_hard.predict(X_test)\n",
        "accuracy_hard = accuracy_score(y_test, y_pred_hard)\n",
        "\n",
        "# Guardar el modelo y los resultados\n",
        "joblib.dump(voting_clf_hard, 'Voting_Hard_model.pkl')\n",
        "joblib.dump(y_pred_hard, 'Voting_Hard_pred.pkl')\n",
        "joblib.dump(accuracy_hard, 'Voting_Hard_accuracy.pkl')\n",
        "\n",
        "# Entrenar el clasificador por voto mayoritario (soft voting)\n",
        "voting_clf_soft.fit(X_train_sample, y_train_sample)\n",
        "y_pred_soft = voting_clf_soft.predict(X_test)\n",
        "accuracy_soft = accuracy_score(y_test, y_pred_soft)\n",
        "\n",
        "# Guardar el modelo y los resultados\n",
        "joblib.dump(voting_clf_soft, 'Voting_Soft_model.pkl')\n",
        "joblib.dump(y_pred_soft, 'Voting_Soft_pred.pkl')\n",
        "joblib.dump(accuracy_soft, 'Voting_Soft_accuracy.pkl')\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"Precisión del clasificador por voto mayoritario (hard voting) = {accuracy_hard:.4f}\")\n",
        "print(f\"Precisión del clasificador por voto mayoritario (soft voting) = {accuracy_soft:.4f}\")\n",
        "\n",
        "# Mejor precisión individual obtenida anteriormente\n",
        "best_individual_accuracy = 0.9504  # Precisión del SVM\n",
        "\n",
        "# Comparar las precisiones\n",
        "if accuracy_hard > best_individual_accuracy:\n",
        "    print(f\"El clasificador por voto mayoritario (hard voting) es mejor con precisión de {accuracy_hard:.4f}\")\n",
        "else:\n",
        "    print(f\"El mejor clasificador individual (SVM) es mejor con precisión de {best_individual_accuracy:.4f}\")\n",
        "\n",
        "if accuracy_soft > best_individual_accuracy:\n",
        "    print(f\"El clasificador por voto mayoritario (soft voting) es mejor con precisión de {accuracy_soft:.4f}\")\n",
        "else:\n",
        "    print(f\"El mejor clasificador individual (SVM) es mejor con precisión de {best_individual_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-z3fUHE-JAC",
        "outputId": "85cbb85c-b010-4fe7-89db-28e6058a9fa4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del clasificador por voto mayoritario (hard voting) = 0.9155\n",
            "Precisión del clasificador por voto mayoritario (soft voting) = 0.9249\n",
            "El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\n",
            "El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etGp76uxUj_O"
      },
      "source": [
        "- 2.4 Utilice el `mejor modelo individual` hallado en el numeral `2.2` y construya un clasificador con el método `Bagging`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Cargue de el Mejor clasificador individual\n",
        "best_svm = joblib.load('SVM_model.pkl')\n",
        "\n",
        "# Creo el clasificador Bagging usando SVM como estimador base\n",
        "bagging_clf = BaggingClassifier(base_estimator=best_svm, n_estimators=10, random_state=42)\n",
        "\n",
        "# Entreno el clasificador Bagging\n",
        "bagging_clf.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "# Guardo el modelo Bagging\n",
        "joblib.dump(bagging_clf, 'Bagging_model.pkl')\n",
        "\n",
        "# Evaluación en el conjunto test\n",
        "y_pred_bagging = bagging_clf.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "print(f\"Precisión del clasificador Bagging = {accuracy_bagging:.4f}\")\n",
        "\n",
        "# Guardo las Predicciones y Precision del Bagging\n",
        "joblib.dump(y_pred_bagging, 'Bagging_pred.pkl')\n",
        "joblib.dump(accuracy_bagging, 'Bagging_accuracy.pkl')\n",
        "\n",
        "# Comparación de rendimientos\n",
        "print(f\"Comparación de rendimientos:\\n\")\n",
        "print(f\"Precisión del clasificador por voto mayoritario (hard voting) = 0.9155\")\n",
        "print(f\"Precisión del clasificador por voto mayoritario (soft voting) = 0.9249\")\n",
        "print(f\"El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\")\n",
        "print(f\"Precisión del clasificador Bagging = {accuracy_bagging:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixxBtsDvE0GE",
        "outputId": "4140d727-eb76-4bce-dc8e-f2b29126373d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del clasificador Bagging = 0.9501\n",
            "Comparación de rendimientos:\n",
            "\n",
            "Precisión del clasificador por voto mayoritario (hard voting) = 0.9155\n",
            "Precisión del clasificador por voto mayoritario (soft voting) = 0.9249\n",
            "El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\n",
            "Precisión del clasificador Bagging = 0.9501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESPUESTA: Aunque el Bagging tiene un accuracy del 95,01%, superior a los clasificadores por Voto mayoritario (Duro 91.55% y Suave 92.49%) aún sigue siendo más alto por muy poco el de SVM 95.04%"
      ],
      "metadata": {
        "id": "_-5RJRSApDFs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzgxR8I5Uj_P"
      },
      "source": [
        "- 2.5 Utilizando los hiperparámetros del mejor `árbol de decisión` construido en el numeral `2.2`, entrene un `bosque alretorio` y utilice la validación cruzada afinar solamente un hiperparámetro: `n_estimators`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import joblib\n",
        "\n",
        "# Cargo los mejores hiperparámetros del árbol de decisión\n",
        "best_dtree_params = joblib.load('DecisionTree_best_params.pkl')\n",
        "\n",
        "# Defino los parámetros del Random Forest utilizando los hiperparámetros del árbol de decisión\n",
        "rf_params = {\n",
        "    'n_estimators': np.arange(50, 301, 50),  # Solo el número de estimadores se ajusta según el punto 2.5\n",
        "    'max_depth': [best_dtree_params['max_depth']], #10\n",
        "    'min_samples_split': [best_dtree_params['min_samples_split']], #2\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "# Creo el Random Forest\n",
        "rf_clf = RandomForestClassifier()\n",
        "\n",
        "# Optimización y validación cruzada para n_estimators\n",
        "random_search_rf = RandomizedSearchCV(rf_clf, rf_params, cv=5, scoring='accuracy', n_iter=10, n_jobs=-1, random_state=42)\n",
        "random_search_rf.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "# Mejor estimador\n",
        "best_rf = random_search_rf.best_estimator_\n",
        "\n",
        "# Guardar el mejor modelo y los mejores parámetros\n",
        "joblib.dump(best_rf, 'RandomForest_model.pkl')\n",
        "joblib.dump(random_search_rf.best_params_, 'RandomForest_best_params.pkl')\n",
        "\n",
        "print(f\"Mejor configuración para Random Forest:\")\n",
        "print(random_search_rf.best_params_)\n",
        "print(f\"Precisión media de validación cruzada: {random_search_rf.best_score_:.4f}\")\n",
        "\n",
        "# valuación Test\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "# Guardo las predicciones y la precisión\n",
        "joblib.dump(y_pred_rf, 'RandomForest_pred.pkl')\n",
        "joblib.dump(accuracy_rf, 'RandomForest_accuracy.pkl')\n",
        "\n",
        "# Precisión del clasificador Random Forest\n",
        "print(f\"Precisión del clasificador Random Forest = {accuracy_rf:.4f}\")\n",
        "\n",
        "# Comparación de rendimientos\n",
        "print(\"\\nComparación de rendimientos:\")\n",
        "print(f\"Precisión del clasificador Reg Log = 0.4564\")\n",
        "print(f\"Precisión del clasificador K-Vecinos = 0.9299\")\n",
        "print(f\"Precisión del clasificador Decision Tree = 0.7891\")\n",
        "print(f\"Precisión del clasificador Naive Bayes = 0.6105\")\n",
        "\n",
        "print(f\"Precisión del clasificador por voto mayoritario (hard voting) = 0.9155\")\n",
        "print(f\"Precisión del clasificador por voto mayoritario (soft voting) = 0.9249\")\n",
        "print(f\"El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\")\n",
        "print(f\"Precisión del clasificador Bagging = 0.9501\")\n",
        "print(f\"Precisión del clasificador Random Forest = {accuracy_rf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYL9FwDysDB5",
        "outputId": "88df77fa-fde0-4bce-d0f4-88752f8fcf09"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración para Random Forest:\n",
            "{'random_state': 42, 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 10}\n",
            "Precisión media de validación cruzada: 0.9355\n",
            "Precisión del clasificador Random Forest = 0.9306\n",
            "\n",
            "Comparación de rendimientos:\n",
            "Precisión del clasificador Reg Log = 0.4564\n",
            "Precisión del clasificador K-Vecinos = 0.9299\n",
            "Precisión del clasificador Decision Tree = 0.7891\n",
            "Precisión del clasificador Naive Bayes = 0.6105\n",
            "Precisión del clasificador por voto mayoritario (hard voting) = 0.9155\n",
            "Precisión del clasificador por voto mayoritario (soft voting) = 0.9249\n",
            "El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\n",
            "Precisión del clasificador Bagging = 0.9501\n",
            "Precisión del clasificador Random Forest = 0.9306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESPUESTA: El Random Forest mejoror el accuracy 0.9306 respecto al decision tree 0.7891, pero aún sigue siendo el SVM el que presenta mejor resultado 0.9504"
      ],
      "metadata": {
        "id": "tvsJNyFV33Xv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzN18cDTUj_P"
      },
      "source": [
        "- 2.6 Utilice el `mejor modelo individual` hallado en el numeral `2.2` y contruya un clasificador con el método `AdaBoost`y utilice la validación cruzada afinar solamente dos hiperparámetros: `n_estimators` y `learning_rate`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: Intente primero estos hiperparametros\n",
        "'n_estimators': [10, 50, 100, 200], # Numero de arboles\n",
        "'learning_rate': [0.01, 0.1, 1, 10]\n",
        "pero el tiempo de proceso tardo 2.45 horas y no termino, decidí ajustar 'n_estimators': [50, 100] y 'learning_rate': [0.01, 0.1]\n",
        "tambien pase de n_iter=10 a 5\n",
        "\n",
        "Nota_2: Ejecute con SVM por unas 5 horas, el proceso nunca termino, use el segundo mejor clasificador que es K-vecinos con 0.9299 pero no es posible para un adaboost ya que no puedo ajustar el parametro, sample_weight, asi que realice el ejercicio con el tercer mejor clasificador individual que es un decision tree, este ultimo pudo ejecutarse en 53.52 Minutos ajuste los hiperparametros 'n_estimators': [10, 50, 100, 200], # Numero de arboles\n",
        "'learning_rate': [0.01, 0.1, 1, 10], CV = 5, n_iter = 10"
      ],
      "metadata": {
        "id": "o7ewtOosc92n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Cargo los mejores hiperparámetros guardados para Decision Tree\n",
        "dt_best_params = joblib.load('DecisionTree_best_params.pkl')\n",
        "\n",
        "# Creo el modelo Decision Tree con los mejores hiperparámetros\n",
        "best_dt = DecisionTreeClassifier(**dt_best_params)\n",
        "\n",
        "# Configuro el clasificador AdaBoost con el modelo base (Decision Tree)\n",
        "ada_clf = AdaBoostClassifier(base_estimator=best_dt)\n",
        "\n",
        "# Defino el rango de hiperparámetros para n_estimators y learning_rate\n",
        "ada_params = {\n",
        "    'n_estimators': [10, 50, 100, 200],  # Número de árboles\n",
        "    'learning_rate': [0.01, 0.1, 1, 10]  # Tasa de aprendizaje\n",
        "}\n",
        "\n",
        "# Búsqueda de hiperparámetros con validación cruzada\n",
        "random_search_ada = RandomizedSearchCV(ada_clf, ada_params, cv=5, scoring='accuracy', n_iter=10, n_jobs=-1, random_state=42)\n",
        "random_search_ada.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "# Mejor estimador\n",
        "best_ada = random_search_ada.best_estimator_\n",
        "\n",
        "# Guardo el mejor modelo AdaBoost\n",
        "joblib.dump(best_ada, 'AdaBoost_model_DT.pkl')\n",
        "\n",
        "# Guardo los mejores hiperparámetros\n",
        "joblib.dump(random_search_ada.best_params_, 'ada_best_params_DT.pkl')\n",
        "\n",
        "# Imprimo la mejor configuración y la precisión media de validación cruzada\n",
        "print(f\"Mejor configuración para AdaBoost con Decision Tree:\")\n",
        "print(random_search_ada.best_params_)\n",
        "print(f\"Precisión media de validación cruzada: {random_search_ada.best_score_:.4f}\")\n",
        "\n",
        "# Evaluación en el conjunto de test\n",
        "y_pred_ada = best_ada.predict(X_test)\n",
        "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
        "\n",
        "# Guardo las predicciones y la precisión\n",
        "joblib.dump(y_pred_ada, 'AdaBoost_pred_DT.pkl')\n",
        "joblib.dump(accuracy_ada, 'AdaBoost_accuracy_DT.pkl')\n",
        "\n",
        "# Imprimo la precisión en el conjunto de test\n",
        "print(f\"AdaBoost con Decision Tree: Precisión en el conjunto de prueba = {accuracy_ada:.4f}\")\n",
        "\n",
        "# Se Comparan las precisiones\n",
        "best_individual_accuracy = 0.7891  # Precisión del DT\n",
        "\n",
        "if accuracy_ada > best_individual_accuracy:\n",
        "    print(f\"El clasificador AdaBoost con Decision Tree es mejor con precisión de {accuracy_ada:.4f}\")\n",
        "else:\n",
        "    print(f\"El mejor clasificador individual (DT) es mejor con precisión de {best_individual_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1hEW2x74M1e",
        "outputId": "28e95975-884b-40e9-b057-c84afb66bdf6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración para AdaBoost con Decision Tree:\n",
            "{'n_estimators': 200, 'learning_rate': 10}\n",
            "Precisión media de validación cruzada: 0.9472\n",
            "AdaBoost con Decision Tree: Precisión en el conjunto de prueba = 0.9420\n",
            "El clasificador AdaBoost con Decision Tree es mejor con precisión de 0.9420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESPUESTA: El resultado del Adaboost en cuanto a accuracy es de un 0.9420 respecto al DT esto es una mejora de 0.1529 en accuracy y\n",
        "respecto a los otros modelos sigue siendo el SVM el de mayor accuracy 0.9504"
      ],
      "metadata": {
        "id": "hdQKqAAW6oUJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TVGjuyoUj_P"
      },
      "source": [
        "- 2.7 Utilizando los hiperparámetros del mejor `árbol de decisión` construido en el numeral `2.2`, entrene un `GradientBoostingClassifier` y utilice la validación cruzada afinar solamente dos hiperparámetros: `n_estimators` y `learning_rate`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Cargo los mejores hiperparámetros del árbol de decisión\n",
        "best_dtree_params = joblib.load('DecisionTree_best_params.pkl')\n",
        "\n",
        "# GradientBoostingClassifier con los hiperparámetros del mejor árbol de decisión\n",
        "gbc = GradientBoostingClassifier(\n",
        "    max_depth=best_dtree_params['max_depth'],\n",
        "    min_samples_split=best_dtree_params['min_samples_split'],\n",
        "    min_samples_leaf=best_dtree_params.get('min_samples_leaf', 1),\n",
        "    max_leaf_nodes=best_dtree_params.get('max_leaf_nodes', None)\n",
        ")\n",
        "\n",
        "# Ajuste de hiperparametros\n",
        "gbc_params = {\n",
        "    'n_estimators': [50, 100],  # Numero de arboles\n",
        "    'learning_rate': [0.01, 0.05] # pasos que da el modelo en pro de minimizar el error\n",
        "}\n",
        "\n",
        "# Optimización y validación cruzada para GradientBoostingClassifier\n",
        "random_search_gbc = RandomizedSearchCV(gbc, gbc_params, cv=3, scoring='accuracy', n_iter=5, n_jobs=-1, random_state=42)\n",
        "random_search_gbc.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "best_gbc = random_search_gbc.best_estimator_\n",
        "joblib.dump(best_gbc, 'GradientBoosting_model.pkl')  # Guardo el mejor modelo GB\n",
        "\n",
        "print(f\"Mejor configuración para GradientBoostingClassifier:\")\n",
        "print(random_search_gbc.best_params_)\n",
        "print(f\"Precisión media de validación cruzada: {random_search_gbc.best_score_:.4f}\")\n",
        "joblib.dump(random_search_gbc.best_params_, 'GradientBoosting_best_params.pkl')\n",
        "\n",
        "# Evaluación en el conjunto de Test\n",
        "y_pred_gbc = best_gbc.predict(X_test)\n",
        "accuracy_gbc = accuracy_score(y_test, y_pred_gbc)\n",
        "joblib.dump(y_pred_gbc, 'GradientBoosting_pred.pkl')\n",
        "joblib.dump(accuracy_gbc, 'GradientBoosting_accuracy.pkl')\n",
        "\n",
        "print(f\"GradientBoostingClassifier: Precisión en el conjunto de prueba = {accuracy_gbc:.4f}\")\n",
        "\n",
        "# Comparación con modelos anteriores\n",
        "print(\"\\nComparación de rendimientos:\")\n",
        "print(f\"Precisión del clasificador por voto mayoritario (hard voting) = 0.9155\")\n",
        "print(f\"Precisión del clasificador por voto mayoritario (soft voting) = 0.9249\")\n",
        "print(f\"El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\")\n",
        "print(f\"Precisión del clasificador Bagging = 0.9501\")\n",
        "print(f\"Precisión del clasificador AdaBoost = 0.9420\")\n",
        "print(f\"Precisión del GradientBoostingClassifier = {accuracy_gbc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhB4ACD16nP3",
        "outputId": "d86a3001-3fa4-4c8c-9cd1-314ff3842eea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración para GradientBoostingClassifier:\n",
            "{'n_estimators': 100, 'learning_rate': 0.05}\n",
            "Precisión media de validación cruzada: 0.9003\n",
            "GradientBoostingClassifier: Precisión en el conjunto de prueba = 0.9156\n",
            "\n",
            "Comparación de rendimientos:\n",
            "Precisión del clasificador por voto mayoritario (hard voting) = 0.9155\n",
            "Precisión del clasificador por voto mayoritario (soft voting) = 0.9249\n",
            "El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\n",
            "Precisión del clasificador Bagging = 0.9501\n",
            "Precisión del clasificador AdaBoost = 0.9420\n",
            "Precisión del GradientBoostingClassifier = 0.9156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESPUESTA: Resultado del GradientBoostingClassifier, presenta un accuracy de 0.9156, lo cual representa un 0.1265 mejor accuracy que el arbol con 0.7891, al comparar vs e mejor modelo, aún sigue siendo mejor el SVM con 0.9504"
      ],
      "metadata": {
        "id": "C-gF5-oCJU0z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M8cbeXsUj_P"
      },
      "source": [
        "- 2.8 Utilizando los hiperparámetros del mejor `árbol de decisión` construido en el numeral `2.2`, entrene un `XGBClassifier` y utilice la validación cruzada afinar solamente dos hiperparámetros: `n_estimators` y `learning_rate`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Cargo los mejores hiperparámetros del árbol de decisión\n",
        "best_dtree_params = joblib.load('DecisionTree_best_params.pkl')\n",
        "\n",
        "# XGBClassifier con los hiperparámetros del mejor árbol de decisión\n",
        "xgb = XGBClassifier(\n",
        "    max_depth=best_dtree_params['max_depth'],\n",
        "    min_child_weight=best_dtree_params.get('min_samples_split', 1),\n",
        "    gamma=best_dtree_params.get('min_samples_leaf', 0),\n",
        "    max_delta_step=best_dtree_params.get('max_leaf_nodes', 0)\n",
        ")\n",
        "\n",
        "# Hiperparámetros\n",
        "xgb_params = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Convertir las etiquetas a tipo int\n",
        "y_train_sample = y_train_sample.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "# Optimización y validación cruzada para XGBClassifier\n",
        "random_search_xgb = RandomizedSearchCV(xgb, xgb_params, cv=3, scoring='accuracy', n_iter=5, n_jobs=-1, random_state=42)\n",
        "random_search_xgb.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "best_xgb = random_search_xgb.best_estimator_\n",
        "joblib.dump(best_xgb, 'XGB_model.pkl')  # Guardo el mejor modelo XGB\n",
        "\n",
        "print(f\"Mejor configuración para XGBClassifier:\")\n",
        "print(random_search_xgb.best_params_)\n",
        "print(f\"Precisión media de validación cruzada: {random_search_xgb.best_score_:.4f}\")\n",
        "joblib.dump(random_search_xgb.best_params_, 'XGB_best_params.pkl')\n",
        "\n",
        "# Evaluación en el conjunto de test\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "joblib.dump(y_pred_xgb, 'XGB_pred.pkl')\n",
        "joblib.dump(accuracy_xgb, 'XGB_accuracy.pkl')\n",
        "\n",
        "print(f\"XGBClassifier: Precisión en el conjunto de prueba = {accuracy_xgb:.4f}\")\n",
        "\n",
        "# Comparar con los modelos anteriores\n",
        "print(\"\\nComparación de rendimientos:\")\n",
        "print(f\"Precisión del clasificador por voto mayoritario (hard voting) = 0.9155\")\n",
        "print(f\"Precisión del clasificador por voto mayoritario (soft voting) = 0.9249\")\n",
        "print(f\"El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\")\n",
        "print(f\"Precisión del clasificador Bagging = 0.9501\")\n",
        "print(f\"Precisión del clasificador AdaBoost = 0.9420\")\n",
        "print(f\"Precisión del GradientBoostingClassifier = 0.9156\")\n",
        "print(f\"Precisión del XGBClassifier = {accuracy_xgb:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucSaya158aRs",
        "outputId": "8fccf6ec-b0e5-4242-f912-134d91f7459a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración para XGBClassifier:\n",
            "{'n_estimators': 100, 'learning_rate': 0.2}\n",
            "Precisión media de validación cruzada: 0.9327\n",
            "XGBClassifier: Precisión en el conjunto de prueba = 0.9381\n",
            "\n",
            "Comparación de rendimientos:\n",
            "Precisión del clasificador por voto mayoritario (hard voting) = 0.9155\n",
            "Precisión del clasificador por voto mayoritario (soft voting) = 0.9249\n",
            "El mejor clasificador individual (SVM) es mejor con precisión de 0.9504\n",
            "Precisión del clasificador Bagging = 0.9501\n",
            "Precisión del clasificador AdaBoost = 0.9420\n",
            "Precisión del GradientBoostingClassifier = 0.9156\n",
            "Precisión del XGBClassifier = 0.9381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESPUESTA: EL XGBClassifier presenta un accuracy del 0.9381, representando un aumento de 0.149 sobre el decision Tree, pero sigue siendo el SVM mejor accuracy con 0.9504"
      ],
      "metadata": {
        "id": "lhGLUsa1I1ba"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o5dBFMnUj_P"
      },
      "source": [
        "- 2.9 Elija `el mejor clasificador` de entre todos los entrenados previamente y argumente su respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESPUESTA: El mejor clasificador según los resultados definidos en el accuracy es el SVM con un 95,04%, aunque tiene un costo computacional alto, el resto de los clasificadores no lograron superar el indicador,  "
      ],
      "metadata": {
        "id": "f_DYgtzY86Lm"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}